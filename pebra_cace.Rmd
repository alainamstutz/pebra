---
title: "PEBRA Complier Average Causal Effect Analyses"
author: "A.Amstutz & N.Tschumi"
date: "2023-05-07"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
    code_folding: hide
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

# Load packages

```{r load packages, include=FALSE}
library(tidyverse)
library(readxl)
library(tableone)
library(data.table)
library(writexl)
library(lme4)
library(msm)
library(sjPlot) # for tab_model
library(jtools) # for summ()
library(sandwich) # for robust sandwich SE

```

# Load Data
```{r, include=FALSE}
enrolment <- read_excel("data/0m_enrolment.xls")
twelve_month <- read_excel("data/12m_status_VL_ART_20210505.xls")
status_6 <- read_excel("data/6m_status.xls") 
baseline_VL <- read_excel("data/0m_VL_2xlsx.xls")
# all intervention peer educators
pe_1 <- read_excel("data/cheezy_pa.xls")
pe_2 <- read_excel("data/itu_pa.xls")
pe_3 <- read_excel("data/johnnie_pa.xls")
pe_4 <- read_excel("data/leekay_pa.xls")
pe_5 <- read_excel("data/luciah_pa.xls")
pe_6 <- read_excel("data/mc_pa.xls")
pe_7 <- read_excel("data/more1_pa.xls")
pe_8 <- read_excel("data/nono_pa.xls")
pe_9 <- read_excel("data/sk_pa.xls")
pe_10 <- read_excel("data/tlikso_pa.xls")

```

# Load functions

```{r functions, include=FALSE}
# functions used for PEBRA main analyses for main results publication

percentage_table <- function(variable1,variable2){
  df <- table(variable1,variable2,useNA = "ifany")
  df_per_1 <- paste0(paste0("(",paste0(round(df[,1]/sum(df[,1])*100,2),"%")),")")
  df_per_2 <- paste0(paste0("(",paste0(round(df[,2]/sum(df[,2])*100,2),"%")),")")
  df_per_1 <- paste(df[,1],df_per_1)
  df_per_2 <- paste(df[,2],df_per_2)
  df_per <- cbind(df_per_1,df_per_2)
  colnames(df_per) <- colnames(df)
  rownames(df_per) <- rownames(df)
  rownames(df_per)[is.na(rownames(df_per))]<-"missing"
  return(df_per)
}

percentage_table_incl_total <- function(variable1,variable2){
  df <- table(variable1,variable2,useNA = "ifany")
  df <- cbind(df,table(variable1,useNA = "ifany"))
  colnames(df)[3]<-"total"
  df_per_1 <- paste0(paste0("(",paste0(round(df[,1]/sum(df[,1])*100,2),"%")),")")
  df_per_2 <- paste0(paste0("(",paste0(round(df[,2]/sum(df[,2])*100,2),"%")),")")
  df_per_3 <- paste0(paste0("(",paste0(round(df[,3]/sum(df[,3])*100,2),"%")),")")
  df_per_1 <- paste(df[,1],df_per_1)
  df_per_2 <- paste(df[,2],df_per_2)
  df_per_3 <- paste(df[,3],df_per_3)
  df_per <- cbind(df_per_1,df_per_2,df_per_3)
  colnames(df_per) <- colnames(df)
  rownames(df_per) <- rownames(df)
  rownames(df_per)[is.na(rownames(df_per))]<-"missing"
  return(df_per)
}
percentage_table_woutNA <- function(variable1,variable2){
  df <- table(variable1,variable2)
  df_per_1 <- paste0(paste0("(",paste0(round(df[,1]/sum(df[,1])*100,2),"%")),")")
  df_per_2 <- paste0(paste0("(",paste0(round(df[,2]/sum(df[,2])*100,2),"%")),")")
  df_per_1 <- paste(df[,1],df_per_1)
  df_per_2 <- paste(df[,2],df_per_2)
  df_per <- cbind(df_per_1,df_per_2)
  colnames(df_per) <- colnames(df)
  rownames(df_per) <- rownames(df)
  return(df_per)
}

# delta method to get confidence intervals
# https://migariane.github.io/DeltaMethodEpiTutorial.nb.html
get_confint_delta <- function(fit){
  se_or_delta <- mapply(FUN = function(b1,vb1){deltamethod(~ exp(x1), b1, vb1)},
                        fixef(fit), diag(vcov.merMod(fit)))
  grad <- exp(fixef(fit))
  return(data.frame(CI_l = grad-1.96*se_or_delta,CI_u = grad+1.96*se_or_delta))
}

#get confint pasted
paste_confint <- function(confint){
  paste0(paste0(paste0(paste0("(",round(confint[1,],2))," to "),round(confint[2,],2)),")")
}

binary_satisfaction <- function(a){
  if (is.na(a)){return(NA)}
  else if (a %in% c("Very satisfied")){return(1)}
  else {return(0)}}

```

# Data management
### Preference assessments (intervention peer-educator data only)

```{r, include=FALSE}
# merge pa's from different intervention clinics
all_pa <- bind_rows(pe_1,pe_2,pe_3,pe_4,pe_4,pe_5,pe_6,pe_7,pe_8,pe_9,pe_10)

# delete duplicates

# all_pa_cleaned <- c()
# noduplicates_frame <- c()
# 
# ## all rows from unique ID
# for (j in unique(all_pa$IND_ID)){
#   ## safe in temporary df
#   noduplicates_frame <- all_pa[which(all_pa$IND_ID==j),]
#   ## order df by date
#   noduplicates_frame <- noduplicates_frame[order(noduplicates_frame$DATE_CREATED),]
#   if (nrow(noduplicates_frame) > 1) {
#     ## every row in df
#     for (rec in (nrow(noduplicates_frame)-1):1) {
#       ## compare with next to follow
#       if (noduplicates_frame$DATE_CREATED [rec] == noduplicates_frame$DATE_CREATED [rec+1]){
#         ## if they have an identical date, delete first row
#         noduplicates_frame <- noduplicates_frame [-rec,]
#       }
#     }
#   }
#   ## merge data frames from single patients into one df again
#   all_pa_cleaned <- bind_rows(all_pa_cleaned, noduplicates_frame)
# }
# all_pa <- all_pa_cleaned

# delete duplicates
all_pa <- all_pa %>% 
  distinct()

# # # recode all true and false (and NA) to numeric
# all_pa[all_pa == "true"] <- 1
# all_pa[all_pa == "false"] <- 2
# all_pa[is.na(all_pa)] <- 0

# replace refill with SCC if ART Refill = 1 (clinic) and SUPPORT SCC = true (= SCC wished and available)
table(all_pa$SUPPORT_SCC, useNA = "always")
class(all_pa$SUPPORT_SCC)

table(all_pa$ART_REFILL_1, useNA = "always")
class(all_pa$ART_REFILL_1)

all_pa <- all_pa %>%
  mutate(ART_REFILL_1 = case_when(SUPPORT_SCC == "true" & ART_REFILL_1 == "1" ~ "6",
                                   TRUE ~ c(ART_REFILL_1)))

```

```{r, include=FALSE}
# Add enrollment date
all_pa <- merge(all_pa, enrolment[, c("DATE_ENROL", "IND_ID")], by = "IND_ID")

# Preference assessment per ID
unique(all_pa$IND_ID)
all_pa %>%
  summarise(median = median(table(IND_ID)),
            IQR = IQR(table(IND_ID)),
            Q1 = quantile(table(IND_ID), probs = 0.25),
            Q3 = quantile(table(IND_ID), probs = 0.75))

## sort our first, middle and last assessment of each patient
start_pa <- data.frame()
end_pa <- data.frame()
mid_pa <- data.frame()

# loop all PAs by participant
for (j in unique(all_pa$IND_ID)){
  # put all assessments of patient in one df
  id_frame <- all_pa[which(all_pa$IND_ID==j),]
  # order df by assessment date
  id_frame <- id_frame[order(id_frame$DATE_CREATED),]
  # START PA: safe first row = first assessment of patient in new df
  start_id_frame <- head(id_frame, n=1)
  colnames(start_id_frame) <- paste0(colnames(start_id_frame),"_start")
  # MID PA: between 5 and 7 months from first assessment
  mid_id_new <- id_frame[as.Date(id_frame$DATE_CREATED) < (as.Date(id_frame$DATE_CREATED[1]) + months(7)),]
  mid_id_new <- id_frame[as.Date(id_frame$DATE_CREATED) >= (as.Date(id_frame$DATE_CREATED[1]) + months(5)),]
  # chose first option if there is multiple
  mid_id_frame <- head(mid_id_new, n=1)
  colnames(mid_id_frame) <- paste0(colnames(mid_id_frame),"_mid")
  # LAST PA: safe last row = last assessment of patient in new df
  end_id_frame <- tail(id_frame, n=1)
  colnames(end_id_frame) <- paste0(colnames(end_id_frame),"_end")
  # bind first assessments from all patients to new df
  start_pa <- bind_rows(start_pa, start_id_frame)
  # bind middle assessments from all patients to new df
  mid_pa <- bind_rows(mid_pa, mid_id_frame)
  # bind last assessments from all patients to new df
  end_pa <- bind_rows(end_pa, end_id_frame)
}

start_pa <- start_pa %>% 
  select(IND_ID_start, PE_start, ID_start, DATE_CREATED_start, TIME_CREATED_start, DATE_ENROL_start, everything())
end_pa <- end_pa %>% 
  select(IND_ID_end, PE_end, ID_end, DATE_CREATED_end, TIME_CREATED_end, DATE_ENROL_end, everything())
mid_pa <- mid_pa %>% 
  select(IND_ID_mid, PE_mid, ID_mid, DATE_CREATED_mid, TIME_CREATED_mid, DATE_ENROL_mid, everything())

# tableone <- tableone::CreateTableOne(data = start_pa,vars = start_pa_vars[!start_pa_vars == "GENDER"],strata = "GENDER",includeNA = TRUE,test = FALSE,addOverall = TRUE)
# 
# capture.output(tableone <- print(tableone, nonnormal = start_pa_vars,catDigits = 1,SMD = TRUE,showAllLevels = TRUE,test = FALSE,printToggle = FALSE,missing = FALSE))
#
# #print
# knitr::kable(tableone,caption = "Baseline assessment of Notifications, missing values in categorical variables: NAs")

```

### Baseline preference assessment data only

```{r work with baseline PA, include=FALSE}
# rename variables that we don't want to be double
start_pa <- start_pa %>% 
  rename(IND_ID = IND_ID_start)

# Unpack Support Option String
class(start_pa$SUPPORT_start)
unique(start_pa$SUPPORT_start)
table(start_pa$SUPPORT_start)
# library(stringr)
# start_pa$SUPPORT_start2 <- strsplit(start_pa$SUPPORT_start, ", ")
# class(start_pa$SUPPORT_start2)

start_pa <- start_pa %>% ## classify nurse support only as No, everyone else chose some pe support
  mutate(pe_support = case_when(grepl("1", SUPPORT_start) == TRUE & 
                                  grepl("2", SUPPORT_start) == FALSE & 
                                  grepl("3", SUPPORT_start) == FALSE &
                                  grepl("4", SUPPORT_start) == FALSE &
                                  grepl("5", SUPPORT_start) == FALSE &
                                  grepl("6", SUPPORT_start) == FALSE &
                                  grepl("7", SUPPORT_start) == FALSE &
                                  grepl("8", SUPPORT_start) == FALSE &
                                  grepl("9", SUPPORT_start) == FALSE &
                                  grepl("10", SUPPORT_start) == FALSE &
                                  grepl("11", SUPPORT_start) == FALSE &
                                  grepl("12", SUPPORT_start) == FALSE &
                                  grepl("13", SUPPORT_start) == FALSE &
                                  grepl("14", SUPPORT_start) == FALSE ~ "No",
                             TRUE ~ "Yes"))
start_pa %>% ## reclassify the one who ONLY wanted no support at all as "nurse support only" / "no PE support"
  mutate(pe_support = case_when(grepl("14", SUPPORT_start) == TRUE ~ "No",
                             TRUE ~ c(pe_support)))

## there was no-one who ONLY wanted 8= Condom demonstration; or 9= More information about contraceptives; or 10= More information about VMMC; or 11= For pregnant: Linkage to young mothers group (DREAMS or Mothers-to-Mothers); or 12= For females: Linkage to a female WORTH group (Social Asset Building Model); or 13= More information about legal aid and gender-based violence

table(start_pa$SUPPORT_start, useNA = "always")
table(start_pa$pe_support, useNA = "always")

```

### Join to main dataset with all peer-educators and participants
### Sociodemographic characteristics of all participants

```{r, message=FALSE, include=FALSE}
# Add preference assessment data of baseline
df <- left_join(enrolment, start_pa[, c("pe_support", "IND_ID")], by = join_by(IND_ID == IND_ID))
table(df$pe_support, useNA = "always")

# Add 12m data
twelve_month <- twelve_month %>% 
  rename(CurrentARTregimen_end = CurrentARTregimen,
         CurrentARTregimen_other_end = CurrentARTregimen_other,
         CurrentARTregimen_SINCE_WHEN_end = CurrentARTregimen_SINCE_WHEN)
df <- left_join(df, twelve_month[, c("CurrentARTregimen_end", "CurrentARTregimen_other_end", "CurrentARTregimen_SINCE_WHEN_end",
                                            "DATE_CREATED_REFILL", "DATE_NEXT", "REFILL_TYPE", "REFILL_NO", "DEATH_DATE", "DEATH_CAUSE",
                                            "HOSP", "TRANSFER_TO", "TRANSFER_DATE", "ART_STOP", "STATUS", "STATUS_DETAIL", "VL_DATE",
                                            "FAILED", "VL_LTDL", "VL_RESULT", "IND_ID")], by = join_by(IND_ID == IND_ID))
# Add baseline VL
baseline_VL <- baseline_VL %>% 
  rename(VL_LTDL_baseline = VL_LTDL,
         VL_RESULT_baseline = VL_RESULT)
df <- left_join(df, baseline_VL[, c("VL_LTDL_baseline", "VL_RESULT_baseline", "IND_ID")], by = join_by(IND_ID == IND_ID))

# # reclassify the confirmed transfer out as "out of care"
# class(df$STATUS)
# df <- df %>% 
#   mutate(STATUS = case_when(STATUS == "in care" & STATUS_DETAIL == "transfer" ~ "out of care",
#                             TRUE ~ c(STATUS)))

# gender
table(df$GENDER)
df$GENDER <- ifelse(as.numeric(df$GENDER) == 1,"female","male")

# cell phone
table(df$CELL_GIVEN)
df$CELL_GIVEN <- sapply(df$CELL_GIVEN,FUN = function(a){
  if (a == 1){return("Yes")}
  if (a %in% c(2,3)){return("No")}
})

# age at day of enrolment
df$AGE <- as.numeric(difftime(df$DATE_ENROL,df$BIRTHDAY,units = "weeks")/52.143)

# sexual orientation
table(df$SEX_ORIENT)
df$SEX_ORIENT <- sapply(df$SEX_ORIENT,FUN = function(a){
  if (a == 1){return("straight or heterosexual")}
  if (a == 3){return("gay or lesbian")}
  if (a == 4){return("prefer not to answer")}
})

# completed years of school
df$N_school <- with(df,as.numeric(primary)+as.numeric(secondary)+as.numeric(tertiary)+as.numeric(high_school))

# no schooling at all
df$no_schooling <- ifelse(df$N_school == 0,"Yes","No")

# employment
df$employment_yn <- ifelse(df$emplyoment %in% c("No regular income / unemployed","Subsistence farming","Housewife"),yes = "unemp",no = "emp")

# occupation
df$occupation <- mapply(FUN=function(employment,currently_attending){
  if (employment == "unemp" & currently_attending == "Yes"){return("attending school")}
  if (employment == "emp"){return("(self-)employed")}
  if (employment == "unemp" & currently_attending == "No"){return("nothing")}
},df$employment_yn,df$currently_attending)

# profession
table(df$profession)
tab <- table(df$profession)<3
df$profession <- ifelse(df$profession %in% c(names(tab[tab]),"Other"),"Other",df$profession)

# pregnant or breastfeeding
df$pregnant_breastfeeding <- sapply(xor(df$Pregnant == "Yes",df$Breastfeeding == "Yes"),FUN = function(a){
  if (is.na(a)){return(NA)}
  else if (a == TRUE){return("Yes")}
  else if (a == FALSE){return("No")}
})
df$pregnant_breastfeeding[df$GENDER=="male"]<-NA
df$pregnant_breastfeeding[df$GENDER=="female" & is.na(df$pregnant_breastfeeding)]<- "No"
table(df$pregnant_breastfeeding, df$GENDER, useNA = "always")

# contraceptive use
# sterilized : 0
table(df$fp_other)
df$fp_inject[which(df$fp_other==1)]<-1
df$fp_other[which(df$fp_other==1)]<-0
df$fp_calendar <- ifelse(as.numeric(df$fp_calendar)==1,"Yes","No")
df$fp_condom <- ifelse(as.numeric(df$fp_condom) ==1,"Yes","No")
df$fp_pill <- ifelse(as.numeric(df$fp_pill) ==1,"Yes","No")
df$fp_withdraw <- ifelse(as.numeric(df$fp_withdraw)==1,"Yes","No")
df$fp_inject <- ifelse(as.numeric(df$fp_inject)==1,"Yes","No")
df$fp_other <- ifelse(as.numeric(df$fp_other)==1,"Yes","No")
df$fp_no_answer <- ifelse(as.numeric(df$fp_no_answer)==1,"Yes","No")

# how many children (add 0 if NA)
df$Howmany[is.na(df$Howmany)] <- 0
df <- df %>% 
  mutate(Howmany = case_when(Howmany == "2" | Howmany == "3" ~ "2 or 3",
                             TRUE ~ Howmany))

# number of correctly answered HIV knowledge questions
df$N_HIV_question <- with(df,mapply(FUN = sum,kissing == "No",kitchen == "No",touching == "No",men_to_women == "Yes",women_to_men == "Yes",partners == "No",washing == "No",pregnant_to_baby == "Yes",virgin == "No",cure == "No"))

# expenses
df$expenses_transport_yn <- sapply(df$expenses_transport, FUN = function(a){
  if(a == "1"){return("yes")}
  else {return("no")}
    })
df$expenses_transport_cost <- as.numeric(df$expenses_transport_cost)
df$expenses_food_yn <- sapply(df$expenses_food, FUN = function(a){
  if(a == "1"){return("yes")}
  else {return("no")}
    })
df$expenses_food_cost <- as.numeric(df$expenses_food_cost)

# marital status
table(df$Maritalstatus)
df$Maritalstatus <- ifelse(df$Maritalstatus %in% c("divorced","separated","widowed"),"div/sep/wid",df$Maritalstatus)

```

### TABLE Baseline characteristics by group: socio-demographics

```{r, echo=TRUE}
# table for sociodemographic characteristics
vars.list <- c("ARM","GENDER","AGE","CELL_GIVEN","SEX_ORIENT","currently_attending","no_schooling","N_school","emplyoment","occupation","profession","Maritalstatus","pregnant_breastfeeding","Howmany","using_fp","fp_condom","fp_pill","fp_inject","fp_withdraw","fp_calendar","fp_other","fp_no_answer","N_HIV_question","expenses_transport_yn","expenses_transport_cost","expenses_food_yn","expenses_food_cost")

df_sociodemo <- df[,colnames(df)%in%vars.list]
df_sociodemo <- df_sociodemo[,match(vars.list,colnames(df_sociodemo))]
colnames(df_sociodemo) <- vars.list <- c("ARM","Gender","Age at enrolment","Cell phone to receive confidential information","Sexual orientation","Currently attending school","No schooling","Number of completed school years","Employment","Occupation","Profession (if (self-)employed)","Marital status","Pregnant  or breastfeeding","Number of children","Contraception use","Contraception: Condom use (male and female)","Contraception: Contraceptive pill","Contraception: Injectable or Implant (e.g. DEPO)","Contraception: Withdraw","Contraception: Calendar method","Contraception: other","Contraception: no answer","Number of correctly answered HIV knowledge questions (maximum 10)","Expenses: transport","Expenses: transport costs","Expenses: food","Expenses: food costs")

table_sociodemo <- tableone::CreateTableOne(data = df_sociodemo,vars = vars.list[!vars.list == "ARM"],strata = "ARM",includeNA = TRUE,test = FALSE,addOverall = TRUE)

capture.output(table_sociodemo <- print(table_sociodemo, nonnormal = vars.list,catDigits = 1,SMD = TRUE,showAllLevels = TRUE,test = FALSE,printToggle = FALSE,missing = TRUE))

#print
knitr::kable(table_sociodemo,caption = "Baseline characteristics: socio-demographic, missing values in categorical variables: NAs")

```

### Clinical characteristics of all participants

```{r include=FALSE}
# year of HIV diagnosis
df$diagnosis_year_cat <- sapply(df$DateofHIVdiagnosis,FUN=function(a){
  a <- as.Date(a)
  if (a >= as.Date("2005-01-01") & a < as.Date("2010-01-01")){return("2005-2009")}
  if (a >= as.Date("2010-01-01") & a < as.Date("2015-01-01")){return("2010-2014")}
  if (a >= as.Date("2015-01-01") & a < as.Date("2020-01-01")){return("2015-2020")}
})
df$time_diag_enrol <- as.numeric(difftime(df$DATE_ENROL,df$DateofHIVdiagnosis,units = "weeks")/52.14)

# year of ART start
df$artstart_year_cat <- sapply(df$art_start_date,FUN=function(a){
  a <- as.Date(a)
  if (a >= as.Date("2005-01-01") & a < as.Date("2010-01-01")){return("2005-2009")}
  if (a >= as.Date("2010-01-01") & a < as.Date("2015-01-01")){return("2010-2014")}
  if (a >= as.Date("2015-01-01") & a < as.Date("2020-01-01")){return("2015-2020")}
})
df$time_artstart_enrol <- as.numeric(difftime(df$DATE_ENROL,df$art_start_date,units = "weeks")/52.14)

# year of HIV infection
df$infection_year_cat <- sapply(df$infection_year,FUN=function(a){
  a <- as.Date(a)
  if (a >= as.Date("1995-01-01") & a < as.Date("2000-01-01")){return("1995-1999")}
  if (a >= as.Date("2000-01-01") & a < as.Date("2005-01-01")){return("2000-2004")}
  if (a >= as.Date("2005-01-01") & a < as.Date("2010-01-01")){return("2005-2009")}
  if (a >= as.Date("2010-01-01") & a < as.Date("2015-01-01")){return("2010-2014")}
  if (a >= as.Date("2015-01-01") & a < as.Date("2020-01-01")){return("2015-2020")}
})
df$time_infection_enrol <- as.numeric(difftime(df$DATE_ENROL,df$infection_year,units = "weeks")/52.14)

# current ART regimen
table(df$CurrentARTregimen,useNA = "always")
table(df$CurrentARTregimen_other, useNA = "always")
df$CurrentARTregimen[df$CurrentARTregimen == "ABC/3TC/Kaletra(LPV/r)"] <- "ABC/3TC/LPV/r"
df$CurrentARTregimen[df$CurrentARTregimen == "TDF/3TC/Kaletra(LPV/r)"] <- "TDF/3TC/LPV/r"
df$CurrentARTregimen[df$CurrentARTregimen == "TDF/3TC/DTG (=TLD)"] <- "TDF/3TC/DTG"
df$CurrentARTregimen[df$CurrentARTregimen == "other"] <- df$CurrentARTregimen_other[df$CurrentARTregimen == "other"]
df <- df %>% 
  mutate(CurrentARTregimen = case_when(CurrentARTregimen == "ABC 3TC DTG" ~ "ABC/3TC/DTG",
                                       CurrentARTregimen == "AZT 3TC DTG" ~ "AZT/3TC/DTG",
                                       TRUE ~ CurrentARTregimen))

df$CurrentARTregimen[grepl("EFV",df$CurrentARTregimen)] <- "EFV-based"
df$CurrentARTregimen[grepl("NVP",df$CurrentARTregimen)] <- "NVP-based"
df$CurrentARTregimen[grepl("LPV/r",df$CurrentARTregimen)] <- "LPV/r-based"
df$CurrentARTregimen[grepl("DTG",df$CurrentARTregimen)] <- "DTG-based"

# ART regimen at endpoint
table(df$CurrentARTregimen_end,useNA = "always")
table(df$CurrentARTregimen_other_end, useNA = "always")
df$CurrentARTregimen_end[df$CurrentARTregimen_end == "ABC/3TC/Kaletra(LPV/r)"] <- "ABC/3TC/LPV/r"
df$CurrentARTregimen_end[df$CurrentARTregimen_end == "TDF/3TC/Kaletra(LPV/r)"] <- "TDF/3TC/LPV/r"
df$CurrentARTregimen_end[df$CurrentARTregimen_end == "TDF/3TC/DTG (=TLD)"] <- "TDF/3TC/DTG"
df <- df %>% 
  mutate(CurrentARTregimen_end = case_when(CurrentARTregimen_end == "other" ~ "ETV/3TC/LPV/r (3rd line)",
                                       TRUE ~ CurrentARTregimen_end))

df$CurrentARTregimen_end[grepl("EFV",df$CurrentARTregimen_end)] <- "EFV-based"
df$CurrentARTregimen_end[grepl("NVP",df$CurrentARTregimen_end)] <- "NVP-based"
df$CurrentARTregimen_end[grepl("LPV/r",df$CurrentARTregimen_end)] <- "LPV/r-based"
df$CurrentARTregimen_end[grepl("DTG",df$CurrentARTregimen_end)] <- "DTG-based"

#cd4 at art start
df$cd4_start_cat <- factor(sapply(as.numeric(df$cd4_start),FUN = function(a){
  if(is.na(a)) {return(NA)}
  else if (a < 200) {return("<200")}
  else if (a >= 500) {return(">499")}
  else {return("200-499")}
}))

df$cd4_start_cat <- relevel(df$cd4_start_cat,ref = "200-499")
df$cd4_start_cat <- relevel(df$cd4_start_cat,ref = "<200")

#baseline viral load
table(df$VL_LTDL_baseline, df$VL_RESULT_baseline, useNA = "always")

df$baseline_Vl_cat <- factor(sapply(df$VL_RESULT_baseline, FUN = function(a){
  a <- as.numeric(a)
  if (is.na(a)){return(NA)}
  else if (a < 20){return("<20")}
  else if (a >= 20 & a <1000){return("20-999")}
  else if (a>=1000){return(">999")}
}))
table(df$baseline_Vl_cat, useNA = "always")
df$baseline_Vl_cat <- relevel(df$baseline_Vl_cat,ref="20-999")
df$baseline_Vl_cat <- relevel(df$baseline_Vl_cat,ref="<20")

# Add transmission way
table(df$infection_way, useNA = "always")
class(df$infection_way)
df <- df %>% 
  mutate(infection_mode = case_when(infection_way == "Through my mother" ~ "vertical",
                                    infection_way == "Blood products" | infection_way == "Sex with a man" 
                                    | infection_way == "Sex with a woman" | infection_way == "Other" ~ "horizontal",
                                    TRUE ~ c(infection_way)))
table(df$infection_mode, useNA = "always")
table(df$infection_way_other, useNA = "always")

```

### TABLE Clinical characteristics by group: socio-demographics

```{r, echo=TRUE}
# table for clinical characteristics
vars.list <- c("diagnosis_year_cat","time_diag_enrol","artstart_year_cat",
                   "time_artstart_enrol","infection_year_cat","time_infection_enrol",
                   "CurrentARTregimen","Currently_TBx","cd4_start_cat",
                   "baseline_Vl_cat","infection_way","ARM")

df_clinical <- df[,colnames(df)%in%vars.list]
df_clinical <- df_clinical[,match(vars.list,colnames(df_clinical))]

colnames(df_clinical) <- vars.list <- c("Year of HIV diagnosis","Years since HIV diagnosis","Year of starting ART","Years since starting ART","Year of HIV infection","Years since HIV infection","Current ART regimen","Currently on TB treatment","CD4 count at ART start", "Baseline viral load","How do you believe you were infected with HIV?","ARM")

table_clinical <- tableone::CreateTableOne(data = df_clinical,vars = vars.list[!vars.list == "ARM"],strata = "ARM",includeNA = TRUE,test = FALSE,addOverall = TRUE)

capture.output(table_clinical <- print(table_clinical, nonnormal = vars.list,catDigits = 1,SMD = TRUE,showAllLevels = TRUE,test = FALSE,printToggle = FALSE,missing = TRUE))

#print
knitr::kable(table_clinical,caption = "Baseline characteristics: clinical, missing values in categorical variables: NAs")

```

# Primary endpoint

The primary outcome of the trial is:

In care with documented viral suppression at 12 months, defined as the proportion of participants in care with a documented VL \<20 copies/mL 12 months (range: 9 -- 15 months) after enrolment out of all participants enrolled

i.  If several viral loads are available in the primary endpoint window, then the result closest to the 12-months endpoint (date of enrolment + 365 days) will be considered.

ii. Rational for VL suppression level at 20 copies/mL: VL determination will be done on COBAS TaqMan HIV-1 Test, v2.0 (Roche Diagnostics) using plasma, and has a reliable lower limit of detection of 20 copies/mL

iii. Definition of "in care": at least one ART visit in the defined window

<!-- -->

I.  Participants who transferred out to any other health facility with known outcome are considered in care (documented proof VL within the primary endpoint window)

II. Participants who died (all-cause), were lost to follow-up (LTFU), or were alive, not taking ART anymore are considered out of care. We define participants lost to follow-up if they or their treatment buddies were more than 2 months late for a scheduled consultation or medication pick-up and no information was found about the participant. We define participants alive, not taking ART anymore if they were more than 2 months late for ART refill with a reason available (e.g. currently no money for clinic-visit, busy working in South Africa, known refusers, known defaulters, etc.)

<!-- -->

iv. The study will use VL results from routine VL monitoring. To synchronize routine VL monitoring and study VL monitoring, study staff will help ensure each site has the capacity to collect these samples and will support existing systems that help to provide results back to sites. VLs will only be performed on individuals who return for visits and no tracking besides standard of care will be performed by the study staff to obtain VLs.

```{r,echo = TRUE,results='markup'}
# endpoint definition
df$VL_DATE <- as.Date(df$VL_DATE)
df$VL_RESULT <- as.numeric(df$VL_RESULT)

# endpoint window (9-15)
df$endpoint_l <- as.Date(df$DATE_ENROL) + 252
df$endpoint_u <- as.Date(df$DATE_ENROL) + 450

# definition endpoint
fun_endpoint <- function(VL,VL_date,endpoint_l,endpoint_u,status){
  if (is.na(VL)){return(0)}
  else if (VL >= 20){return(0)}
  else if (status == "out of care"){return(0)}
  else if (xor(VL_date < endpoint_l,VL_date > endpoint_u)){return(0)}
  else {return(1)}}

df$endpoint_reached <- with(df,mapply(fun_endpoint,
  VL_RESULT,VL_DATE,endpoint_l,endpoint_u,STATUS))

# table(df$endpoint_reached, useNA = "always")
tab <- table(df$endpoint_reached)
rownames(tab) <- c(">=20","<20")

# print
knitr::kable(tab,caption = "reached primary endpoint")

```

### VL endpoint overview

```{r,echo = TRUE,results='markup'}
tab <- percentage_table(df$endpoint_reached,df$ARM)
rownames(tab) <- c(">=20","<20")
# print
knitr::kable(tab,caption = "reached primary endpoint, by arm")

fun_endpoint_detail <- function(VL,VL_date,endpoint_l,endpoint_u,status){
  if (status == "out of care"){return("out of care")}
  else if (is.na(VL)){return("in care, VL missing")}
  else if (xor(VL_date < endpoint_l,VL_date > endpoint_u)){return("VL out of window")}
  else if (VL < 20){return("VL < 20")}
  else if (VL >= 20 && VL < 1000){return("VL 20-999")}
  else if (VL >= 1000){return("VL > 999")}}
  
df$endpoint_detail <- with(df,mapply(fun_endpoint_detail,
  VL_RESULT,VL_DATE,endpoint_l,endpoint_u,STATUS))

tab <- percentage_table(df$endpoint_detail,df$ARM)
tab <- tab[c(2,1,3,5,4,6),]

# print
knitr::kable(tab,caption = "primary endpoint detail, by arm")

out_of_window <- df[df$endpoint_detail == "VL out of window",]
tab <- percentage_table(out_of_window$VL_RESULT<20,out_of_window$ARM)
rownames(tab) <- c(">=20","<20")

# print
knitr::kable(tab,caption = "VLs of those out of window, by arm")

```

# Primary ITT analysis

For the analysis of the primary outcome, we will use a multi-level logistic regression model including clinic as a random effect, arm allocation and the randomisation stratification factor (district) as a fixed effect. **Gender was included in the analysis as a relevant baseline factors found to be randomly unbalanced between intervention and control arm**. Unavailability of a viral load or invalid VL result in the predefined primary endpoint window (for any reason) will be considered as failures. Results will be reported as odds ratios with 95% confidence intervals **and p-values**.

```{r echo=TRUE, message=FALSE}
# use logit link to obtain ORs
fit <- glmer(endpoint_reached ~ ARM + (1|USER) + DISTRICT + GENDER, data = df,
              family = binomial(link = "logit"))

#### adjust for baseline VL, to increase power, use different methods (see https://www.bmj.com/content/360/bmj.k1121.long)
# first, as naive adjustment
fit <- glmer(endpoint_reached ~ DISTRICT + ARM + GENDER + (1|USER) + baseline_Vl_cat, 
              data = df, 
              family = binomial(link = "logit"))
# mean cluster value
df$VL_RESULT_baseline <- as.numeric(df$VL_RESULT_baseline)
df <- df %>% 
  mutate(baseline_Vl_num = case_when(baseline_Vl_cat == "<20" ~ 0,
                                     baseline_Vl_cat == ">999" ~ VL_RESULT_baseline,
                                     baseline_Vl_cat == "20-999" ~ VL_RESULT_baseline))
result <- df %>%
  group_by(USER) %>%
  drop_na(baseline_Vl_num) %>% 
  summarize(baseline_Vl_meanUSER = mean(baseline_Vl_num))
df <- left_join(df, result[, c("baseline_Vl_meanUSER", "USER")], by = join_by(USER == USER)) ## merge imputed

# individual-level ANCOVA with cluster-level adjustment
fit <- glmer(endpoint_reached ~ DISTRICT + ARM + GENDER + (1|USER) + baseline_Vl_meanUSER, 
              data = df, 
              family = binomial(link = "logit"))

## Now with Constrained baseline analysis
# Define the number of times you want to duplicate the dataset
num_duplicates <- 2
# Duplicate the dataset
df_dup <- rep(list(df), times = num_duplicates)
# Combine the duplicated datasets into one
df_dup <- do.call(rbind, df_dup)
# Reset the row names if needed
rownames(df_dup) <- NULL
# Create a new column "time" and assign values 0 and 1 to each of the clones, corresponding to 0=baseline and 1=follow-up
df_dup$time <- rep(0:1, each = nrow(df_dup) / 2)
# Add the baseline VL to the baseline clone
# create same definition variable for baseline
df_dup <- df_dup %>% 
  mutate(baseline_endpoint_reached = case_when(baseline_Vl_cat == "<20" ~ 1,
                                               baseline_Vl_cat == "20-999" | baseline_Vl_cat == ">999" ~ 0))
df_dup <- df_dup %>% 
  mutate(endpoint_reached = case_when(time == 0 ~ baseline_endpoint_reached,
                           TRUE ~ endpoint_reached))
# Create the treatment variable by period (=time)
df_dup <- df_dup %>% 
  mutate(treat = case_when(ARM == "interv." & time == 1 ~ 1,
                           TRUE ~ 0))

# df_dup %>%
#   select(time, USER, IND_ID, ARM, treat, endpoint_reached, baseline_endpoint_reached) %>%
#   View()

# constrained baseline analysis – inflexible correlation structure
fit <- glmer(endpoint_reached ~ time + treat + (1|USER) 
             + DISTRICT + GENDER 
              ,data = df_dup, 
              family = binomial(link = "logit"))
# constrained baseline analysis – flexible correlation structure
fit <- glmer(endpoint_reached ~ time + treat + (1|USER) + (1|USER:time)
             + DISTRICT + GENDER 
              ,data = df_dup, 
              family = binomial(link = "logit"))
tab_model(fit) # compare to primary below below!

# class(fit)
primary <- df %>% 
  glmer(endpoint_reached ~ DISTRICT + ARM + GENDER + (1|USER), 
              family = binomial(link = "logit"), data=.)
tab_model(primary)
summ(primary, exp = T, confint = T, model.info = F, model.fit = F, digits = 3)
summ(primary, exp = F, confint = F, model.info = F, model.fit = F, digits = 3)
# primary <- df %>% 
#   glmer(endpoint_reached ~ DISTRICT + ARM + GENDER + (1|USER), 
#               family = binomial(link = "logit"), data=.) %>% 
#   confint.merMod(method="Wald") %>% 
#   exp()

# class(primary)

# exp(fixef(fit))
# summary(fit)$coefficients

#confidence intervals
confint <- exp(confint.merMod(primary,method="Wald"))
confint <- t(confint[!rownames(confint)%in%c("(Intercept)",".sig01"),])

data <- data.frame(
  "odds ratio" = round(exp(fixef(primary)[names(fixef(primary))!="(Intercept)"]),2),
  "confidence interval" = paste_confint(confint),
  "p-value" = round(summary(primary)$coefficients[,4][names(summary(primary)$coefficients[,4])!="(Intercept)"],3))

# ordering A on top
data <- data[order(rownames(data)),]           

knitr::kable(data,caption = "individual-level analysis adjusted for district and gender")
```

# Explore small sample correction

```{r}
# small sample correction should be taken into account (https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-022-01699-2) -> use p-values from a t-distribution with degrees of freedom as clusters minus cluster-level parameters / and use restricted pseudolikelihood (RPL) estimation instead of REML if convergence issues

# Extract estimated coefficients and standard errors
coefs <- coef(summary(fit))[, "Estimate"]
std_errors <- coef(summary(fit))[, "Std. Error"]

odds_ratio <- exp(coefs)

# Calculate the t-values
t_values <- coefs / std_errors

# number of clusters
n_clusters <- length(unique(df$USER))
# Correct the degrees of freedom (Clusters minus cluster-level parameters: Leribe, MKG, Male, Arm, Intercept)
df_correction <- n_clusters - 5

# Calculate the p-values based on the t-values and degrees of freedom
p_values <- 2 * pt(abs(t_values), df = df_correction, lower.tail = FALSE)

# Calculate the critical value from the t-distribution for the desired confidence level
t_critical <- qt(0.975, df = df_correction)

# Calculate the confidence intervals using the modified degrees of freedom
conf_intervals <- t_critical * std_errors

# Calculate the lower and upper limits of the confidence intervals
lower_limit <- exp(coefs - conf_intervals)
upper_limit <- exp(coefs + conf_intervals)

# Combine all // very similar point estimate but slightly increases uncertainty -> keep original model
results <- cbind(coefs, odds_ratio, std_errors, t_values, p_values, lower_limit, upper_limit)
print(results)

```


# Sensitivity analysis on ITT set

### Wider Endpoint window

We use a wider window for the primary endpoint, namely 9-18 months.

```{r,echo = TRUE,message=FALSE}
# endpoint window
df$endpoint_l <- as.Date(df$DATE_ENROL) + 252
df$endpoint_u_alternative <- as.Date(df$DATE_ENROL) + (30*18)

# defintion endpoint alternative
fun_endpoint_alternative <- function(VL,VL_date,endpoint_l,endpoint_u_alternative,status){
  if (is.na(VL)){return(0)}
  else if (VL >= 20){return(0)}
  else if (status == "out of care"){return(0)}
  else if (xor(VL_date < endpoint_l,VL_date > endpoint_u_alternative)){return(0)}
  else {return(1)}}

df$endpoint_reached_alt <- with(df,mapply(fun_endpoint_alternative,
  VL_RESULT,VL_DATE,endpoint_l,endpoint_u_alternative,STATUS))

tab <- percentage_table(df$endpoint_reached_alt,df$ARM)
# print
knitr::kable(tab,caption = "primary endpoint reached with wider endpoint window, by arm")

# use logit link to obtain ORs
fit <- glmer(endpoint_reached_alt ~ DISTRICT + ARM + GENDER + (1|USER), 
              data = df, 
              family = binomial(link = "logit"))
tab_model(fit)

#confidence intervals
confint <- exp(confint.merMod(fit,method="Wald"))
confint <- t(confint[!rownames(confint)%in%c("(Intercept)",".sig01"),])

data <- data.frame("odds ratio" = round(exp(fixef(fit)[names(fixef(fit))!="(Intercept)"]),2),
           "confidence interval" = paste_confint(confint),
           "p-value" = round(summary(fit)$coefficients[,4][names(summary(fit)$coefficients[,4])!="(Intercept)"],3))

# order by A
data <- data [order(rownames(data)),]           

# print
knitr::kable(data,caption = "primary endpoint with 9-18 window: individual-level analysis adjusted for district and gender")
```


# "Per-protocol set/analysis" (according to protocol/publication)

We analyse the individual-based per protocol set, considering participants who have 1. a documented 6 month visit (range: 5 -- 8 months); and **(this was the only difference compared to primary analysis)** 2. a documented 12 months visit with viral load measurement (range: 9 -- 15 months).

```{r,echo = TRUE,message=FALSE}
df$status_6 <- status_6$STATUS[match(df$STICKER_ID,status_6$STICKER_ID)]
df$REFILL_NO_6 <- status_6$REFILL_NO[match(df$STICKER_ID,status_6$STICKER_ID)]
df$endpoint_reached_pp <- df$endpoint_reached 
df$endpoint_reached_pp[df$status_6 == "out of care"] <- 0

tab <- percentage_table(df$endpoint_reached_pp,df$ARM)
# print
knitr::kable(tab,caption = "reached primary endpoint per protocol, by arm")

fit <- glmer(endpoint_reached_pp ~ DISTRICT + ARM + GENDER + (1|USER), 
              data = df, 
              family = binomial(link = "logit"))
tab_model(fit)

confint <- exp(confint.merMod(fit,method="Wald"))
confint <- t(confint[!rownames(confint)%in%c("(Intercept)",".sig01"),])
data <- data.frame("odds ratio" = round(exp(fixef(fit)[names(fixef(fit))!="(Intercept)"]),2),
           "confidence interval" = paste_confint(confint),
           "p-value" = round(summary(fit)$coefficients[,4][names(summary(fit)$coefficients[,4])!="(Intercept)"],3))

# order by A
data <- data [order(rownames(data)),]           
      
# print
knitr::kable(data,caption = "per-protocol individual-level analysis adjusted for district and gender")
```

# Complier Average Causal Effect (CACE) analysis (i.e., optimized per-protocol analysis)

The ITT analysis estimates a "policy-level" estimate, meaning the effect if PEBRA model is being implemented at a health facility, irrespective of uptake and adherence to the care model by individual participants.
The per-protocol analysis according to protocol/publication excludes participants with missing VL measurements at 6 and 12 months. This is based on a strong assumption that participants with missing VL measurements are not different to those participants with available VL measurements with respect to all predictors of outcome since it compromises randomization. Moreover, it is still a "policy-level" estimate; it does not tell a patient or a clinician what the effect of the PEBRA model is if a patient adheres to the model as intended. Besides, the non-uptake in the intervention dilutes both these trial estimates.
A better option is to conduct a *Complier Average Causal Effect (CACE)* analysis. We plan to use two methods for such a CACE analysis: 1) instrumental variable (IV) analysis and 2) propensity score (PS) matched or weighted analysis. These methods are based on different underlying assumptions, we will discuss them in each chapter. Both analyses ideally deal with a situation whereby the intervention is administered at one time point only since the definition of non-uptake/-compliance/-adherence to the intervention is based on one overall value, i.e. the "point compliance". Therefore, we first define the point compliance in PEBRA. This is a reasonable assumption. However, we may extend the analysis to a situation whereby the intervention is administered over time and thus, time-varying non-uptake/-compliance/-adherence is taken into account ("sustained compliance"), using g-estimation methods.

## First, we define a reasonable "point compliance" in PEBRA intervention.

This analysis shall answers the question: "What would be the treatment effect if participants would have chosen the PEBRA model?" So, this includes all participants that chose any peer-educator support vs those that chose only nurse support (i.e. not the PEBRA model) => variable pe_support (see above)

### TABLE characteristics by group and by complier within intervention group

```{r echo=TRUE}
# pe_support
table(df$pe_support, useNA = "always") # 11 wanted ONLY nurse-support, i.e., did not choose PEBRA model.

df <- df %>% 
  mutate(endpoint_reached_f = case_when(endpoint_reached == 1 ~ "Below 20 c/mL",
                                endpoint_reached == 0 ~ "Above 20 c/mL or missing"))
df <- df %>% 
  mutate(pe_support = case_when(pe_support == "Yes" ~ "Accepted PEBRA",
                                pe_support == "No" ~ "Refused PEBRA",
                                TRUE ~ "Refused PEBRA"))

# table for sociodemographic characteristics
vars.list <- c("ARM","pe_support","GENDER","AGE","CELL_GIVEN","SEX_ORIENT","currently_attending","no_schooling","N_school","emplyoment","occupation","profession","Maritalstatus","pregnant_breastfeeding","Howmany","using_fp","N_HIV_question","expenses_transport_yn","expenses_transport_cost","expenses_food_yn","expenses_food_cost","diagnosis_year_cat","time_diag_enrol","artstart_year_cat","time_artstart_enrol","infection_year_cat","time_infection_enrol","CurrentARTregimen","Currently_TBx","cd4_start_cat","baseline_Vl_cat","infection_mode","endpoint_reached_f")

df_cace <- df[,colnames(df)%in%vars.list]
df_cace <- df_cace[,match(vars.list,colnames(df_cace))]

colnames(df_cace) <- vars.list <- c("ARM","complier","Gender","Age at enrolment","Cell phone to receive confidential information","Sexual orientation","Currently attending school","No schooling","Number of completed school years","Employment","Occupation","Profession (if (self-)employed)","Marital status","Pregnant  or breastfeeding","Number of children","Contraception use","Number of correctly answered HIV knowledge questions (maximum 10)","Expenses: transport","Expenses: transport costs","Expenses: food","Expenses: food costs","Year of HIV diagnosis","Years since HIV diagnosis","Year of starting ART","Years since starting ART","Year of HIV infection","Years since HIV infection","Current ART regimen","Currently on TB treatment","CD4 count at ART start","Baseline viral load","How do you believe you were infected with HIV?","Primary endpoint reached as per primary analysis")

char_vars <- c("Gender", "Cell phone to receive confidential information","Sexual orientation","Currently attending school","No schooling","Employment","Occupation","Profession (if (self-)employed)","Marital status","Pregnant  or breastfeeding","Number of children", "Contraception use","Expenses: transport","Expenses: food","Year of HIV diagnosis","Year of starting ART","Year of HIV infection","Current ART regimen","Currently on TB treatment","CD4 count at ART start","Baseline viral load","How do you believe you were infected with HIV?","Primary endpoint reached as per primary analysis")

# Convert character variables to factors
df_cace <- df_cace %>%
  mutate(across(all_of(char_vars), factor))

# take special care of ARM and complier and primary endpoint
df_cace <- df_cace %>% 
  mutate(ARM = case_when(ARM == "control" ~ 0,
                         ARM == "interv." ~ 1))
df_cace$ARM <- factor(df_cace$ARM, levels = c(0, 1))

df_cace <- df_cace %>% 
  mutate(complier = case_when(complier == "Refused PEBRA" ~ 0,
                         complier == "Accepted PEBRA" ~ 1))
df_cace$complier <- factor(df_cace$complier, levels = c(0, 1))

df_cace <- df_cace %>% 
  mutate(`Primary endpoint reached as per primary analysis` = case_when(`Primary endpoint reached as per primary analysis` == "Above 20 c/mL or missing" ~ 0,
                         `Primary endpoint reached as per primary analysis` == "Below 20 c/mL" ~ 1))
df_cace$`Primary endpoint reached as per primary analysis` <- factor(df_cace$`Primary endpoint reached as per primary analysis`, levels = c(0, 1))

# Correct numeric variables
df_cace$`Number of correctly answered HIV knowledge questions (maximum 10)` <- as.numeric(df_cace$`Number of correctly answered HIV knowledge questions (maximum 10)`)

# Replace empty levels
df_cace <- df_cace %>% 
  mutate(`Pregnant  or breastfeeding` = as.factor(case_when(`Pregnant  or breastfeeding` == "No" ~ "No",
                         `Pregnant  or breastfeeding` == "Yes" ~ "Yes",
                         TRUE ~ "not applicable")))


# intervention arm only (for CreateTableOne)
df_cace_int <- df_cace %>%
  filter(ARM == "1")

table_cace_int <- tableone::CreateTableOne(data = df_cace_int, vars = vars.list[!vars.list %in% c("complier", "ARM")], strata = "complier", includeNA = TRUE, test = TRUE, addOverall = TRUE)

capture.output(table_cace_int <- print(table_cace_int, nonnormal = vars.list,catDigits = 1,SMD = TRUE,showAllLevels = TRUE,test = TRUE,printToggle = FALSE,missing = TRUE))

#print
knitr::kable(table_cace_int,caption = "Baseline characteristics of intervention participants, by compliance to PEBRA model")

# add the overall table
# take out missing and total
table_cace_int <- tableone::CreateTableOne(data = df_cace_int, vars = vars.list[!vars.list %in% c("complier", "ARM")], strata = "complier", includeNA = TRUE, test = FALSE, addOverall = FALSE)
capture.output(table_cace_int <- print(table_cace_int, nonnormal = vars.list,catDigits = 1,SMD = TRUE,showAllLevels = TRUE,test = FALSE,printToggle = FALSE,missing = FALSE))

table_cace <- tableone::CreateTableOne(data = df_cace, vars = vars.list[!vars.list %in% c("complier", "ARM")], strata = "ARM", includeNA = TRUE, test = FALSE, addOverall = FALSE)
capture.output(table_cace <- print(table_cace, nonnormal = vars.list,catDigits = 1,SMD = TRUE,showAllLevels = TRUE,test = FALSE,printToggle = FALSE,missing = FALSE))

#print both alongside
table_cace_overall <- cbind(table_cace, table_cace_int)
knitr::kable(table_cace_overall,caption = "Baseline characteristics by randomization group and of participants that refused or accepted the PEBRA model")

```

## Exploiting the exclusion restriction

To test whether compliance occurs at random (with respect to the outcomes of interest) in the intervention group: were compliance random, then the outcome rates among the non-compliers in the intervention group would be equal to those in the control group. 
We fit a log reg model restricted to non-compliers in the intervention group and all individuals in the control group.
```{r}
df_er <- df %>%
  filter(pe_support == "Refused PEBRA")

table(df_er$ARM, useNA = "always")
er <- df_er %>% 
  glmer(endpoint_reached ~ ARM + DISTRICT + GENDER + (1|USER), 
              family = binomial(link = "logit"), data=.)
tab_model(er)

```
The OR (95% CI) of viral suppression for non-adherents versus controls was 1.30 (0.36-4.74) after adjustment for the variables of the primary model. These estimates indicate that non-compliers and controls have a different risk of viral suppression, and that direct adjustment for the measured baseline characteristics might be insufficient to eliminate the differences. This implies that any method that requires measurement and adjustment for all joint predictors of compliance and outcome (e.g. conventional regression, standardization, inverse probability weighting, propensity score matching, etc.) might be insufficient to eliminate bias. Therefore, to estimate the per protocol effect of PEBRA model on viral suppression, we try first a method that does not require adjustment for joint predictors of compliance and outcome: instrumental variable (IV).

## Investigate further, esp. re predictors for compliance / add OR and 95% to table
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# df_or <- df_cace_int %>% # remove ARM and ENDPOINT and redundant variables (duplicates, used in overall categories, etc.)
#   select("complier","Gender","Age at enrolment","Cell phone to receive confidential information","Sexual orientation", "Number of completed school years", "Occupation", "Marital status", "Pregnant  or breastfeeding","Number of children","Contraception use","Number of correctly answered HIV knowledge questions (maximum 10)","Expenses: transport","Expenses: food","Years since HIV diagnosis","Years since starting ART","Years since HIV infection","Current ART regimen","Currently on TB treatment","CD4 count at ART start","Baseline viral load","How do you believe you were infected with HIV?")

# Fit a logistic regression model
model <- glm(complier ~
               Gender
             + `Age at enrolment`
             + `Cell phone to receive confidential information`
             + `Sexual orientation`
             + `Number of completed school years`
             + Occupation
             + `Marital status`
             + `Pregnant  or breastfeeding`
             + `Number of children`
             + `Number of correctly answered HIV knowledge questions (maximum 10)`
             + `Contraception use`
             + `Expenses: transport`
             + `Expenses: food`
             + `Years since HIV diagnosis`
             + `Years since starting ART`
             + `Years since HIV infection`
             + `Current ART regimen`
             + `Currently on TB treatment`
             + `Baseline viral load`
             + `How do you believe you were infected with HIV?`
               , data = df_cace_int, family = "binomial")

# Extract the coefficients, convert to ORs, round them, extract their standard errors, and calculate 95% CI
coefficients <- coef(summary(model))
odds_ratios <- exp(coefficients[, 1])
odds_ratios_rounded <- round(odds_ratios, digits = 2)
standard_errors <- coefficients[, 2]
lower_ci <- exp(odds_ratios - 1.96 * standard_errors)
upper_ci <- exp(odds_ratios + 1.96 * standard_errors)

# Combine the adjusted Odds Ratios and Confidence Intervals into a data frame
odds_ci_data <- data.frame(odds_ratios_rounded = odds_ratios_rounded,
                           lower_ci = lower_ci,
                           upper_ci = upper_ci)

# Print the data frame with adjusted Odds Ratios and Confidence Intervals
print(odds_ci_data)
knitr::kable(odds_ci_data, caption = "Baseline characteristics predicting acceptance of PEBRA and their odds ratios with 96% confidence intervals, adjusted for all other variables")

```


The table shows that some baseline characteristics were different between the accepters and refusers (age, Number of completed school years, Number of correctly answered HIV knowledge questions (maximum 10), Expenses: transportyes, Years since starting ART, Years since HIV infection, Current ART regimenEFV-based, Current ART regimenNVP-based, Baseline viral load20-999). Valid estimation of the traditional per protocol effect would require adjustment for these and any other prognostic factors that predict compliance. As a result, the per protocol effect cannot be generally estimated via a traditional per protocol analysis that directly compares the outcomes of the PEBRA compliant participants and the controls. 

## Now, we conduct the first CACE analysis, using IV.

IV analyses are based on several assumptions:
1. The instrumental variable (randomization) is associated with the treatment -> true by design
2. There are no unmeasured common causes between randomization and the outcome -> true by design
3. The effect of the randomization on the outcome is fully mediated through the intervention ("exclusion restrictions") -> we cannot fully rule out that intervention refusers were not influenced by the offer of the intervention. Therefore, we will perform the PS analysis as a sensitivity analysis.
4. Monotonicity (i.e. no “defiers”) -> true by design (consent was different by group; groups were blinded to allocation; only participants randomized to the PEBRA model could have received the PEBRA model. No one was prevented from accessing the PEBRA model because they were randomized to the PEBRA model)
5. Stable unit treatment value assumption: one participants’s randomization to the PEBRA model does not affect another participants’s outcome -> true by design (participants were unaware of their randomization status. Randomization was only linked to the offer of the PEBRA model).

Estimation of the CACE is most often done using a “two-stage least squares” (TSLS) approach (Stuart, 2008; 10.1007/s11121-008-0104-y), which jointly models the two processes of compliance and outcome (Angrist and Imbens, 1995). TSLS involves two models: a regression model of compliance, and a regression model predicting the outcome, given compliance. These models are estimated jointly, to calculate accurate standard errors that account for the uncertainty in the “first-stage” (compliance) model. Using TSLS also allows the inclusion of covariates that predict participation and/or the outcome, which can increase the precision of the estimates.

Accordingly, the primary outcome was analysed using a TSLS model with randomization as the instrumental variable and "accepting the PEBRA model" as the treatment variable. In the first stage, the relation between treatment assignment and treatment acceptance (compliance) was estimated.
In the second stage, the effect of the PEBRA model on the outcome was estimated, using the predicted values from the first stage as an independent variable in a logistic regression model.

```{r echo=TRUE}
# In the 2SLS, we will estimate the predicted treatment in the first stage. We can do it by fitting logistic regression for PEBRA acceptance on randomization, important predictors (see previous chapter), and then using the predict command to estimate the probabilities.

# Stage 1 of 2SLS
s1 <- glm(complier ~ ARM 
          + `Age at enrolment` 
          + `Number of completed school years`
          + `Number of correctly answered HIV knowledge questions (maximum 10)`
          + `Expenses: transport`
          + `Years since starting ART`
          + `Years since HIV infection` 
          + `Current ART regimen`
          # + `Baseline viral load`
          , data = df_cace, family = binomial("logit"))
df_cace$complier.new <- NA
df_cace$complier.new <- predict(s1, type = "response")

# In the second stage, we will fit the outcome model (the logistic regression) with the predicted treatment from the first stage and the confounders. We should use the robust sandwich SE to estimate the SE of the treatment effect correctly to account for the clustering effect of multiple observations per subject (Cameron AC, Miller DL. A practitioner's guide to cluster-robust inference. J Hum Resour. 2015;50(2):317-372.)

# Stage 2 of 2SLS
fit.2sls <- glm(`Primary endpoint reached as per primary analysis` ~ complier.new 
          + `Age at enrolment` 
          + `Number of completed school years`
          + `Number of correctly answered HIV knowledge questions (maximum 10)`
          + `Expenses: transport`
          + `Years since starting ART`
          + `Years since HIV infection` 
          + `Current ART regimen`
          # + `Baseline viral load`
          , data = df_cace, family = binomial("logit"))
summ(fit.2sls, exp = T, confint = T, model.info = F, model.fit = F, robust = "HC0")

# as expected, result similar but uncertainty increased
tab_model(fit.2sls)
tab_model(primary)

```

## Now, conduct the second CACE analysis (sensitivity analysis), using PS (check UMBRELLA/Zelen_SSc).

## Re-consider primary endpoint definition re missing outcomes. Consider MICE for missing covariates (SPIN/UMBRELLA)
